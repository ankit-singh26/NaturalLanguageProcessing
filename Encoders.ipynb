{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/tkcHhhhg849FIAaq/cSH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit-singh26/NaturalLanguageProcessing/blob/main/Encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYBzKa6qYbBw"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['I', 'love', 'NLP']\n",
        "encoder = LabelBinarizer()\n",
        "one_hot = encoder.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "FPj5Zq7VZqY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder.classes_)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzZh-8gyZqcO",
        "outputId": "824c25e9-5bfc-42e9-9e6e-4122d3fbb4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I' 'NLP' 'love']\n",
            "[[1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words(CountVectorizer)"
      ],
      "metadata": {
        "id": "G3iWnQPgaXdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "TKKJLymXabhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['I love NLP', 'No NLP here']\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)"
      ],
      "metadata": {
        "id": "J-9UNTFeaipE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(bow.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UQeYuCCaub_",
        "outputId": "c6af9d81-5204-4a0e-f649-0eab96d14987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here' 'love' 'nlp' 'no']\n",
            "[[0 1 1 0]\n",
            " [1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Encoding"
      ],
      "metadata": {
        "id": "_M8YLeVNa59w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "y9hxPiB5a8wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\"I love NLP\", \"NLP loves me\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf = vectorizer.fit_transform(docs)"
      ],
      "metadata": {
        "id": "OzPKd5FCbApq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(tfidf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcpsYNnfbAtC",
        "outputId": "9487999a-cbf3-4804-9a2c-8ca34a4e160e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love' 'loves' 'me' 'nlp']\n",
            "[[0.81480247 0.         0.         0.57973867]\n",
            " [0.         0.6316672  0.6316672  0.44943642]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec(using Gensim)"
      ],
      "metadata": {
        "id": "ISbXlh4jbGd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "qbAEPensbL9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [[\"I\", \"love\", \"NLP\"], [\"NLP\", \"is\", \"awesome\"]]\n",
        "model = Word2Vec(sentences, vector_size=10, window=2, min_count=1)"
      ],
      "metadata": {
        "id": "si1GzoItbNBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv[\"NLP\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXIBithsbNE8",
        "outputId": "19e3cbe0-ccee-40e2-e2be-4410688fc21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
            "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding (simplified version)"
      ],
      "metadata": {
        "id": "EuNk2mxZcDZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "6Gi3XBJQcHlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / d_model)\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    # apply sin to even indices and cos to odd\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    return angle_rads"
      ],
      "metadata": {
        "id": "4Mx_D9R3cMRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_encoding = positional_encoding(seq_len=10, d_model=16)\n",
        "print(pos_encoding.shape)  # (10, 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tfM8O3WcMkq",
        "outputId": "1ba75714-1de9-46ab-d7c1-be29bbcc39c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contextual Embedding (BERT via Transformers)"
      ],
      "metadata": {
        "id": "ppdORe91ciP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "3FK-PZGRcrYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "QprS6HxJdUxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I love NLP\""
      ],
      "metadata": {
        "id": "bvWQN1EidVgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and get input tensors\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "RzypQdAcdVsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "print(cls_embedding.shape)  # (1, 768)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUcrkSUQdWfn",
        "outputId": "558f19dd-2d3b-4c9f-b728-116b3dbed121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 768])\n"
          ]
        }
      ]
    }
  ]
}